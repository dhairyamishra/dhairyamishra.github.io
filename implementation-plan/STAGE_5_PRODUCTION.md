# Stage 5: Production Hardening & Expansion
## Phases 9-11: Security, Monitoring, and Growth

**Duration:** Ongoing  
**Prerequisites:** Stage 4 completed (deployed to GCP)  
**Deliverables:** Secure, monitored, and expandable production system

---

## Overview

This final stage focuses on hardening your production deployment, implementing monitoring and alerting, and preparing for future expansion. You'll secure the VM, set up monitoring, create backup strategies, and learn how to add new project containers.

**Key Goals:**
- Secure the production environment
- Monitor uptime and performance
- Implement backup and recovery procedures
- Enable easy addition of new projects
- Prepare for scaling

---

## Phase 9: Production Hardening + Monitoring

### Objectives
- Secure the VM with firewall and fail2ban
- Enable automatic security updates
- Set up monitoring and alerting
- Implement backup strategies
- Configure log rotation

---

## Task 9.1: Configure UFW Firewall

```bash
# SSH into VM
gcloud compute ssh $VM_NAME --zone=$ZONE --tunnel-through-iap

# Install UFW (if not already installed)
sudo apt-get update
sudo apt-get install -y ufw

# Set default policies
sudo ufw default deny incoming
sudo ufw default allow outgoing

# Allow SSH (be careful!)
sudo ufw allow 22/tcp comment 'SSH'

# Allow HTTP and HTTPS
sudo ufw allow 80/tcp comment 'HTTP'
sudo ufw allow 443/tcp comment 'HTTPS'

# Enable UFW
sudo ufw --force enable

# Check status
sudo ufw status verbose

# List rules with numbers
sudo ufw status numbered
```

**Important:** Make sure SSH is allowed before enabling UFW, or you'll lock yourself out!

---

## Task 9.2: Install and Configure Fail2ban

```bash
# Install fail2ban
sudo apt-get install -y fail2ban

# Create local configuration
sudo cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local

# Edit configuration
sudo nano /etc/fail2ban/jail.local
```

Update the following settings:

```ini
[DEFAULT]
# Ban time: 1 hour
bantime = 1h

# Find time: 10 minutes
findtime = 10m

# Max retry: 3 attempts
maxretry = 3

# Email notifications (optional)
destemail = your@email.com
sendername = Fail2Ban
action = %(action_mwl)s

[sshd]
enabled = true
port = 22
logpath = /var/log/auth.log
maxretry = 3
```

```bash
# Restart fail2ban
sudo systemctl restart fail2ban
sudo systemctl enable fail2ban

# Check status
sudo fail2ban-client status

# Check SSH jail
sudo fail2ban-client status sshd

# View banned IPs
sudo fail2ban-client status sshd | grep "Banned IP"
```

---

## Task 9.3: Enable Unattended Upgrades

```bash
# Install unattended-upgrades
sudo apt-get install -y unattended-upgrades apt-listchanges

# Enable automatic updates
sudo dpkg-reconfigure -plow unattended-upgrades

# Edit configuration
sudo nano /etc/apt/apt.conf.d/50unattended-upgrades
```

Ensure these settings are enabled:

```
// Automatically upgrade security updates
Unattended-Upgrade::Allowed-Origins {
    "${distro_id}:${distro_codename}-security";
};

// Automatically reboot if required
Unattended-Upgrade::Automatic-Reboot "true";
Unattended-Upgrade::Automatic-Reboot-Time "03:00";

// Email notifications
Unattended-Upgrade::Mail "your@email.com";
Unattended-Upgrade::MailReport "on-change";
```

```bash
# Test configuration
sudo unattended-upgrades --dry-run --debug

# Enable automatic updates
sudo systemctl enable unattended-upgrades
sudo systemctl start unattended-upgrades
```

---

## Task 9.4: Configure Log Rotation

### Docker Logs

Already configured in `docker-compose.prod.yml`:

```yaml
logging:
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"
```

### Nginx Logs

Create `/etc/logrotate.d/portfolio-nginx`:

```bash
sudo nano /etc/logrotate.d/portfolio-nginx
```

```
/var/log/nginx/portfolio-*.log {
    daily
    missingok
    rotate 14
    compress
    delaycompress
    notifempty
    create 0640 www-data adm
    sharedscripts
    postrotate
        if [ -f /var/run/nginx.pid ]; then
            kill -USR1 `cat /var/run/nginx.pid`
        fi
    endscript
}
```

Test log rotation:

```bash
sudo logrotate -d /etc/logrotate.d/portfolio-nginx
sudo logrotate -f /etc/logrotate.d/portfolio-nginx
```

---

## Task 9.5: Set Up Monitoring and Alerts

### Install Cloud Monitoring Agent

```bash
# Add Google Cloud Ops Agent repo
curl -sSO https://dl.google.com/cloudagents/add-google-cloud-ops-agent-repo.sh
sudo bash add-google-cloud-ops-agent-repo.sh --also-install

# Verify installation
sudo systemctl status google-cloud-ops-agent
```

### Create Uptime Checks (via GCP Console or gcloud)

```bash
# Create uptime check for homepage
gcloud monitoring uptime-checks create homepage-check \
  --project=$PROJECT_ID \
  --display-name="Homepage Uptime" \
  --resource-type=uptime-url \
  --host=yourdomain.com \
  --path=/ \
  --check-interval=60s

# Create uptime check for API
gcloud monitoring uptime-checks create api-check \
  --project=$PROJECT_ID \
  --display-name="API Health Check" \
  --resource-type=uptime-url \
  --host=yourdomain.com \
  --path=/api/health \
  --check-interval=60s

# Create uptime check for demos
gcloud monitoring uptime-checks create demos-check \
  --project=$PROJECT_ID \
  --display-name="Demos Uptime" \
  --resource-type=uptime-url \
  --host=yourdomain.com \
  --path=/demos/ \
  --check-interval=60s
```

### Set Up Budget Alerts

```bash
# Create budget alert (via GCP Console is easier)
# Go to: Billing ‚Üí Budgets & alerts
# Set budget: $60/month
# Set alerts at: 50%, 90%, 100%
```

### Create Disk Usage Alert

Create `scripts/check_disk_usage.py`:

```python
#!/usr/bin/env python3
"""
Check disk usage and send alert if threshold exceeded
"""
import subprocess
import sys
import smtplib
from email.mime.text import MIMEText

THRESHOLD = 80  # Alert if disk usage > 80%
EMAIL_TO = "your@email.com"
EMAIL_FROM = "noreply@yourdomain.com"

def get_disk_usage():
    """Get disk usage percentage"""
    result = subprocess.run(
        ["df", "-h", "/mnt/data"],
        capture_output=True,
        text=True
    )
    lines = result.stdout.strip().split('\n')
    if len(lines) > 1:
        parts = lines[1].split()
        usage = int(parts[4].rstrip('%'))
        return usage
    return 0

def send_alert(usage):
    """Send email alert"""
    subject = f"‚ö†Ô∏è Disk Usage Alert: {usage}%"
    body = f"""
    Disk usage on /mnt/data has exceeded {THRESHOLD}%.
    
    Current usage: {usage}%
    
    Please check and clean up old files.
    """
    
    msg = MIMEText(body)
    msg['Subject'] = subject
    msg['From'] = EMAIL_FROM
    msg['To'] = EMAIL_TO
    
    # Send via local sendmail or SMTP
    # Configure based on your email setup
    print(f"‚ö†Ô∏è Alert: Disk usage at {usage}%")

def main():
    """Main function"""
    usage = get_disk_usage()
    print(f"Disk usage: {usage}%")
    
    if usage > THRESHOLD:
        send_alert(usage)
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
```

Add to crontab:

```bash
# Edit crontab
crontab -e

# Add daily disk check at 9 AM
0 9 * * * /usr/bin/python3 ~/portfolio/scripts/check_disk_usage.py
```

---

## Task 9.6: Implement Backup Strategy

### Snapshot Persistent Disk

```bash
# Create snapshot manually
gcloud compute disks snapshot portfolio-data-disk \
  --project=$PROJECT_ID \
  --zone=$ZONE \
  --snapshot-names=portfolio-data-$(date +%Y%m%d)

# Create snapshot schedule (automatic daily backups)
gcloud compute resource-policies create snapshot-schedule portfolio-daily-backup \
  --project=$PROJECT_ID \
  --region=$REGION \
  --max-retention-days=7 \
  --on-source-disk-delete=keep-auto-snapshots \
  --daily-schedule \
  --start-time=02:00

# Attach schedule to disk
gcloud compute disks add-resource-policies portfolio-data-disk \
  --project=$PROJECT_ID \
  --zone=$ZONE \
  --resource-policies=portfolio-daily-backup

# List snapshots
gcloud compute snapshots list --project=$PROJECT_ID
```

### Backup Docker Volumes and Configs

Create `scripts/backup_configs.py`:

```python
#!/usr/bin/env python3
"""
Backup important configuration files
"""
import subprocess
import sys
from datetime import datetime
from pathlib import Path

BACKUP_DIR = Path("/mnt/data/backups")
BACKUP_DIR.mkdir(exist_ok=True)

def backup_file(source, dest_dir):
    """Backup a file"""
    try:
        subprocess.run(
            ["cp", "-p", source, dest_dir],
            check=True
        )
        print(f"‚úÖ Backed up: {source}")
        return True
    except Exception as e:
        print(f"‚ùå Failed to backup {source}: {e}")
        return False

def main():
    """Main function"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_subdir = BACKUP_DIR / f"config_{timestamp}"
    backup_subdir.mkdir(exist_ok=True)
    
    print(f"üì¶ Creating backup in {backup_subdir}...\n")
    
    files_to_backup = [
        "/etc/portfolio/.env",
        "/etc/nginx/sites-available/portfolio",
        "~/portfolio/docker-compose.prod.yml",
        "~/portfolio/ecosystem.config.cjs",
    ]
    
    results = []
    for file in files_to_backup:
        results.append(backup_file(file, backup_subdir))
    
    if all(results):
        print(f"\n‚úÖ Backup completed: {backup_subdir}")
        return 0
    else:
        print("\n‚ö†Ô∏è Some files failed to backup")
        return 1

if __name__ == "__main__":
    sys.exit(main())
```

Add to crontab:

```bash
# Weekly config backup on Sundays at 1 AM
0 1 * * 0 /usr/bin/python3 ~/portfolio/scripts/backup_configs.py
```

---

## Task 9.7: Document Rollback Procedure

Create `docs/ROLLBACK.md`:

```markdown
# Rollback Procedure

## Quick Rollback (Git SHA)

If a deployment fails, rollback to a previous version:

```bash
# SSH into VM
gcloud compute ssh portfolio-vm --zone=us-central1-a --tunnel-through-iap

# Navigate to project
cd ~/portfolio

# Find previous working SHA
git log --oneline -n 10

# Set the SHA
export GIT_SHA=abc1234  # Replace with actual SHA

# Pull images with that SHA
docker compose -f docker-compose.prod.yml pull

# Restart services
docker compose -f docker-compose.prod.yml up -d

# Verify
docker compose -f docker-compose.prod.yml logs -f
```

## Restore from Snapshot

If data is corrupted:

```bash
# List snapshots
gcloud compute snapshots list

# Create new disk from snapshot
gcloud compute disks create portfolio-data-disk-restored \
  --source-snapshot=portfolio-data-YYYYMMDD \
  --zone=us-central1-a

# Stop services
docker compose -f docker-compose.prod.yml down

# Detach current disk
gcloud compute instances detach-disk portfolio-vm \
  --disk=portfolio-data-disk \
  --zone=us-central1-a

# Attach restored disk
gcloud compute instances attach-disk portfolio-vm \
  --disk=portfolio-data-disk-restored \
  --zone=us-central1-a

# Mount disk
sudo mount /dev/disk/by-id/google-portfolio-data-disk-restored /mnt/data

# Restart services
docker compose -f docker-compose.prod.yml up -d
```
```

---

## Phase 10: Add /projects/* (Optional Expansion)

### Objectives
- Create template for new project containers
- Add first project container
- Configure routing and deployment
- Update homepage with project card

---

## Task 10.1: Create Project Template

Create `apps/projects/_template/`:

```
apps/projects/_template/
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ package.json (or requirements.txt)
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ index.js (or main.py)
```

### Template Dockerfile

Create `apps/projects/_template/Dockerfile`:

```dockerfile
# Choose base image based on your tech stack
FROM node:20-alpine
# OR
# FROM python:3.11-slim

WORKDIR /app

# Copy dependencies
COPY package*.json ./
# OR
# COPY requirements.txt .

# Install dependencies
RUN npm install
# OR
# RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port (use next available: 8001, 8002, etc.)
EXPOSE 8001

# Run application
CMD ["npm", "start"]
# OR
# CMD ["python", "main.py"]
```

### Template README

Create `apps/projects/_template/README.md`:

```markdown
# Project Template

## Quick Start

1. Copy this template:
   ```bash
   cp -r apps/projects/_template apps/projects/my-project
   cd apps/projects/my-project
   ```

2. Update files:
   - Modify Dockerfile with correct base image and commands
   - Update package.json or requirements.txt
   - Implement your project in src/

3. Choose port (update PORTS.md):
   - Check next available port (8001, 8002, etc.)
   - Update Dockerfile EXPOSE directive

4. Build and test locally:
   ```bash
   docker build -t my-project:latest .
   docker run -p 8001:8001 my-project:latest
   ```

5. Add to docker-compose.prod.yml
6. Add Nginx location block
7. Add project card to homepage
8. Deploy!
```

---

## Task 10.2: Add First Project Container

### Example: AI Chatbot Project

```bash
# Create project directory
mkdir -p apps/projects/chatbot
cd apps/projects/chatbot

# Initialize project (example with Python/Streamlit)
```

Create `apps/projects/chatbot/Dockerfile`:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends curl && \
    rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8001

HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8001/_stcore/health || exit 1

CMD ["streamlit", "run", "app.py", \
     "--server.address", "0.0.0.0", \
     "--server.port", "8001"]
```

Create `apps/projects/chatbot/requirements.txt`:

```txt
streamlit==1.31.0
openai==1.10.0
# Add other dependencies
```

Create `apps/projects/chatbot/app.py`:

```python
import streamlit as st

st.set_page_config(page_title="AI Chatbot", page_icon="ü§ñ")

st.title("ü§ñ AI Chatbot")
st.markdown("An intelligent chatbot powered by AI")

# Your chatbot implementation here
user_input = st.text_input("Ask me anything:")

if user_input:
    st.write(f"You asked: {user_input}")
    # Add AI response logic
```

---

## Task 10.3: Update Port Allocation

Update `PORTS.md`:

```markdown
| chatbot | 8001 | `/projects/chatbot/*` | Active | 2025-12-21 |
```

---

## Task 10.4: Add to Docker Compose

Update `docker-compose.prod.yml`:

```yaml
services:
  # ... existing services ...
  
  project-chatbot:
    image: ${REGISTRY}/us-central1-docker.pkg.dev/${PROJECT_ID}/portfolio/chatbot:${GIT_SHA:-latest}
    container_name: portfolio-chatbot
    ports:
      - "127.0.0.1:8001:8001"
    volumes:
      - /mnt/data/models/chatbot:/app/models:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - portfolio-network
```

---

## Task 10.5: Add Nginx Location Block

Update `infra/nginx/portfolio.conf`:

```nginx
# Add before the catch-all / location

# Chatbot Project
location /projects/chatbot/ {
    proxy_pass http://127.0.0.1:8001/;
    proxy_http_version 1.1;
    
    # WebSocket support (for Streamlit)
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
    
    proxy_set_header Host $host;
    proxy_cache_bypass $http_upgrade;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # Timeouts
    proxy_connect_timeout 300s;
    proxy_send_timeout 300s;
    proxy_read_timeout 300s;
}
```

Deploy Nginx config:

```bash
# SSH into VM
gcloud compute ssh portfolio-vm --zone=us-central1-a --tunnel-through-iap

# Update Nginx config
sudo cp ~/portfolio/infra/nginx/portfolio.conf /etc/nginx/sites-available/portfolio

# Test config
sudo nginx -t

# Reload Nginx
sudo systemctl reload nginx
```

---

## Task 10.6: Add Project Card to Homepage

Update `apps/web/src/content/projects/chatbot.md`:

```markdown
---
title: "AI Chatbot"
description: "Intelligent conversational AI powered by GPT"
tags: ["Python", "OpenAI", "Streamlit", "NLP"]
thumbnail: "/images/chatbot-thumb.png"
demoUrl: "/projects/chatbot"
githubUrl: "https://github.com/yourusername/portfolio"
featured: true
order: 1
---

An interactive AI chatbot that demonstrates natural language processing and conversational AI capabilities.

## Features

- Natural language understanding
- Context-aware responses
- Real-time conversation
- Educational explanations

## Tech Stack

- **Backend**: Python + OpenAI API
- **Frontend**: Streamlit
- **Deployment**: Docker + Nginx
```

---

## Task 10.7: Update GitHub Actions Workflow

Update `.github/workflows/deploy.yml` to build chatbot image:

```yaml
- name: Build and push Chatbot image
  env:
    IMAGE_TAG: ${{ steps.vars.outputs.IMAGE_TAG }}
  run: |
    docker build -t ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }}/chatbot:$IMAGE_TAG ./apps/projects/chatbot
    docker tag ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }}/chatbot:$IMAGE_TAG \
               ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }}/chatbot:latest
    docker push ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }}/chatbot:$IMAGE_TAG
    docker push ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }}/chatbot:latest
```

---

## Task 10.8: Deploy Project

```bash
# Commit and push
git add .
git commit -m "feat: add AI chatbot project"
git push origin main

# GitHub Actions will automatically:
# 1. Build chatbot image
# 2. Push to Artifact Registry
# 3. Deploy to VM

# Verify deployment
curl https://yourdomain.com/projects/chatbot/
```

---

## Phase 11: Launch

### Objectives
- Perform final security audit
- Run performance tests
- Complete documentation
- Launch to production!

---

## Task 11.1: Security Audit Checklist

- [ ] **Firewall configured**: UFW enabled with minimal ports
- [ ] **Fail2ban active**: SSH brute-force protection
- [ ] **Automatic updates**: Unattended upgrades enabled
- [ ] **Secrets secure**: Environment variables in protected file
- [ ] **HTTPS enforced**: HTTP redirects to HTTPS
- [ ] **Security headers**: X-Frame-Options, CSP, etc.
- [ ] **Container binds**: Localhost-only (127.0.0.1)
- [ ] **No exposed ports**: Only Nginx accessible publicly
- [ ] **Input validation**: All API endpoints validate input
- [ ] **Rate limiting**: Contact form and API protected
- [ ] **Honeypot**: Anti-spam measures in place
- [ ] **No PII in logs**: Sensitive data not logged
- [ ] **SSH keys only**: Password authentication disabled
- [ ] **Regular backups**: Snapshots configured
- [ ] **Monitoring active**: Uptime checks and alerts

---

## Task 11.2: Performance Audit

```bash
# Test with Lighthouse
npx lighthouse https://yourdomain.com --view

# Test API response time
curl -w "@curl-format.txt" -o /dev/null -s https://yourdomain.com/api/health

# Load test (optional)
# Use tools like Apache Bench or k6
ab -n 1000 -c 10 https://yourdomain.com/
```

**Target Metrics:**
- Lighthouse Performance: 90+
- Lighthouse SEO: 100
- API response time: < 200ms
- Page load time: < 2s

---

## Task 11.3: Complete Documentation

Ensure all documentation is up to date:

- [ ] README.md with project overview
- [ ] CONTRIBUTING.md with guidelines
- [ ] PORTS.md with port allocations
- [ ] Implementation plan stages
- [ ] API documentation (Swagger/ReDoc)
- [ ] Rollback procedures
- [ ] Monitoring setup
- [ ] Backup procedures

---

## Task 11.4: Final Testing

### End-to-End User Flow

1. **Homepage**: Visit https://yourdomain.com
2. **Navigation**: Test all menu links
3. **Projects**: View project gallery
4. **Demos**: Try ML demos
5. **Contact**: Submit contact form
6. **Mobile**: Test on mobile devices
7. **Performance**: Check load times
8. **SEO**: Verify meta tags and sitemap

### Smoke Tests

```bash
# Run automated smoke tests
python scripts/test_integration.py

# Manual checks
curl -I https://yourdomain.com
curl -I https://yourdomain.com/api/health
curl -I https://yourdomain.com/demos/
```

---

## Task 11.5: Launch! üöÄ

### Pre-Launch Checklist

- [ ] All services running and healthy
- [ ] SSL certificate valid
- [ ] DNS configured correctly
- [ ] Monitoring and alerts active
- [ ] Backups configured
- [ ] Documentation complete
- [ ] Performance optimized
- [ ] Security hardened
- [ ] Contact form tested
- [ ] All links working

### Launch Day

1. **Final deployment**: Merge to main and deploy
2. **Monitor**: Watch logs and metrics
3. **Test**: Run full test suite
4. **Announce**: Share your portfolio!
5. **Celebrate**: You built a production platform! üéâ

---

## Stage 5 Completion Checklist

By the end of Stage 5, you should have:

- [ ] UFW firewall configured
- [ ] Fail2ban protecting SSH
- [ ] Automatic security updates enabled
- [ ] Log rotation configured
- [ ] Monitoring and alerts set up
- [ ] Backup strategy implemented
- [ ] Rollback procedures documented
- [ ] Project template created
- [ ] First project container deployed
- [ ] Security audit completed
- [ ] Performance audit completed
- [ ] All documentation updated
- [ ] Production system launched

---

## Future Enhancements

### Short Term
- Add more ML demos
- Implement analytics (privacy-focused)
- Add blog section
- Create project showcase videos
- Optimize images and assets

### Medium Term
- Add user authentication for demos
- Implement data export features
- Create admin dashboard
- Add more project containers
- Integrate with external APIs

### Long Term
- Scale to multiple VMs (load balancing)
- Add database (PostgreSQL/MongoDB)
- Implement caching (Redis)
- Create mobile app
- Add real-time features (WebSockets)

---

## Maintenance Tasks

### Daily
- Monitor uptime checks
- Review error logs
- Check disk usage

### Weekly
- Review security logs
- Check backup status
- Update dependencies (dev)

### Monthly
- Security audit
- Performance review
- Cost analysis
- Update documentation

### Quarterly
- Major dependency updates
- Infrastructure review
- Disaster recovery test
- Feature planning

---

## Troubleshooting

### High Disk Usage

```bash
# Find large files
du -h /mnt/data | sort -rh | head -20

# Clean up Docker
docker system prune -a

# Clean up old snapshots
gcloud compute snapshots list
gcloud compute snapshots delete old-snapshot-name
```

### Service Down

```bash
# Check service status
docker compose -f docker-compose.prod.yml ps

# View logs
docker compose -f docker-compose.prod.yml logs service-name

# Restart service
docker compose -f docker-compose.prod.yml restart service-name
```

### SSL Certificate Expiring

```bash
# Renew certificate
sudo certbot renew

# Test renewal
sudo certbot renew --dry-run
```

---

## Conclusion

**Congratulations!** üéâ

You've successfully built and deployed a production-ready portfolio platform with:

‚úÖ Modern tech stack (Astro, FastAPI, Streamlit)  
‚úÖ Containerized microservices  
‚úÖ Automated CI/CD pipeline  
‚úÖ Secure HTTPS deployment  
‚úÖ Monitoring and alerting  
‚úÖ Backup and recovery  
‚úÖ Scalable architecture  

Your portfolio is now live and ready to showcase your projects to the world!

---

**Keep building, keep learning, keep growing!** üöÄ
